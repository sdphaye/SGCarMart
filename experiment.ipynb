{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "605417c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180005ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"task1/data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd6b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2024375b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bmw', nan, 'mercedes-benz', 'volvo', 'kia', 'honda', 'nissan',\n",
       "       'toyota', 'mazda', 'ferrari', 'volkswagen', 'jaguar', 'opel',\n",
       "       'mini', 'suzuki', 'porsche', 'lexus', 'lamborghini', 'audi',\n",
       "       'proton', 'hyundai', 'bentley', 'citroen', 'maserati',\n",
       "       'alfa romeo', 'mitsubishi', 'fiat', 'tesla', 'hino', 'skoda',\n",
       "       'land rover', 'rolls-royce', 'mclaren', 'ssangyong', 'renault',\n",
       "       'peugeot', 'subaru', 'isuzu', 'infiniti', 'chevrolet', 'dongfeng',\n",
       "       'cupra', 'ford', 'yutong', 'golden dragon', 'dodge', 'mercedes',\n",
       "       'seat', 'maxus', 'austin', 'mg', 'morris', 'perodua', 'byd',\n",
       "       'rover', 'jeep', 'ud', 'aston martin', 'scania', 'international',\n",
       "       'daf', 'alpine', 'daihatsu', 'lotus', 'hafei', 'chery', 'foton',\n",
       "       'saab', 'hummer', 'iveco', 'riley', 'daimler', 'ruf', 'higer',\n",
       "       'chrysler', 'man', 'joylong', 'mitsuoka'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.make.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d086202",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_series = train_df.title.str.lower()\n",
    "make_series = train_df.make.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f06116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_list = [make for make in make_series.unique() if not pd.isnull(make)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca53d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for indx, comp in make_series.iteritems():\n",
    "    if pd.isnull(comp):\n",
    "        for make in make_list:\n",
    "            if make in title_series[indx]:\n",
    "                make_series[indx] = make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79720cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.make = make_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2011c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in train_df.model.unique():\n",
    "    if pd.isnull(model):\n",
    "        print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb4b94e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bmw', 'toyota', 'mercedes-benz', 'honda', 'volvo', 'kia',\n",
       "       'hyundai', 'mg', 'nissan', 'mazda', 'ferrari', 'volkswagen',\n",
       "       'jaguar', 'opel', 'mini', 'suzuki', 'porsche', 'mitsubishi',\n",
       "       'lexus', 'lamborghini', 'audi', 'proton', 'bentley', 'citroen',\n",
       "       'maserati', 'alfa romeo', 'fiat', 'tesla', 'hino', 'skoda',\n",
       "       'land rover', 'rolls-royce', 'mclaren', 'ssangyong', 'renault',\n",
       "       'peugeot', 'subaru', 'isuzu', 'seat', 'infiniti', 'chevrolet',\n",
       "       'dongfeng', 'cupra', 'ford', 'yutong', 'golden dragon', 'dodge',\n",
       "       'mercedes', 'maxus', 'austin', 'morris', 'perodua', 'byd', 'rover',\n",
       "       'jeep', 'ud', 'aston martin', 'scania', 'international', 'daf',\n",
       "       'alpine', 'daihatsu', 'lotus', 'hafei', 'chery', 'foton', 'saab',\n",
       "       'hummer', 'iveco', 'man', 'riley', 'daimler', 'ruf', 'higer',\n",
       "       'chrysler', 'joylong', 'mitsuoka'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.make.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff1f9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"task1/data/train_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17613024",
   "metadata": {},
   "source": [
    "# Sample instances from dataset and perform clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "891d7954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b7b9f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"task1/data/train_1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4d8e4c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "697d47f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen = np.random.default_rng()\n",
    "# random_int_array = gen.choice(a=16784, size=1000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c1739d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_series = train_df.features\n",
    "features_series.dropna(inplace=True)\n",
    "\n",
    "accessories_series = train_df.accessories\n",
    "accessories_series.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ef9bc132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_rand_series = features_series[random_int_array]\n",
    "# accessories_rand_series = accessories_series[random_int_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "646fb636",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"\\. | \\.|! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "116bcbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_accessory(str_, pattern):\n",
    "    str_1 = str_1.lower()\n",
    "        \n",
    "    if len(str_1) > 1:\n",
    "        str_1 = pattern.sub(\",\", str_1)\n",
    "        str_1 = str_1.strip()\n",
    "        \n",
    "        return [token.strip(string.punctuation+\" \\n\\t\") for token in str_1.split(\",\") if len(token.strip()) > 2]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "57036923",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_2 = set()\n",
    "\n",
    "for accessory in accessories_series.values:\n",
    "    tmp_list = fun(str(accessory), pattern)\n",
    "    for item in tmp_list:\n",
    "        set_2.add(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "449e55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # str_1 = 'low mileage well maintained, 1 owner. view specs of the nissan latio sport'\n",
    "# # str_1 = \"5.7cc ferrari v12 engine, 509 bhp at 7200 rpm, torque: 434 lb ft at 5200 rpm, 0 to 100 4.2sec, quarter mile, 12.6 sec. view specs of the ferrari 575m maranello\"\n",
    "# str_1 = \"3.0l v6 engine. 175kw  power. 293 nm torque. 8.3s  acceleration. 237 km/h top speed. 6 speed  transmission. rear wheel drive. view specs of the jaguar xf \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "776a4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_feature(str_, pattern):\n",
    "    str_1 = str_1.lower()\n",
    "    indx = str_1.find(\"view specs\")\n",
    "    \n",
    "    if indx >= 0:\n",
    "        str_1 = str_1[:indx]\n",
    "        \n",
    "    if len(str_1) > 1:\n",
    "        str_1 = pattern.sub(\",\", str_1)\n",
    "        str_1 = str_1.strip()\n",
    "        \n",
    "        return [token.strip(string.punctuation+\" \\n\\t\") for token in str_1.split(\",\") if len(token.strip()) > 2]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "677817d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_1 = set()\n",
    "\n",
    "for feature in features_series.values:\n",
    "    tmp_list = fun(str(feature), pattern)\n",
    "    for item in tmp_list:\n",
    "        set_1.add(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f9735e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17799\n",
      "19928\n",
      "36331\n"
     ]
    }
   ],
   "source": [
    "print(len(set_1))\n",
    "print(len(set_2))\n",
    "set_1.update(set_2)\n",
    "print(len(set_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a74dbbb",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ad72f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4641c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ed75cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_list = []\n",
    "match_dict = {}\n",
    "encoding_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dfb1c544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 µs, sys: 0 ns, total: 22 µs\n",
      "Wall time: 45.8 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "for text in list(set_1):\n",
    "    text_encoding = model.encode([text])\n",
    "    similar = False\n",
    "    \n",
    "    max_score = None\n",
    "    max_loc = None\n",
    "\n",
    "    for loc in range(len(pool_list)):\n",
    "        sim_score = util.pytorch_cos_sim(encoding_dict[loc], text_encoding).numpy()[0][0]\n",
    "\n",
    "        if sim_score > 0.70:\n",
    "            similar = True\n",
    "            \n",
    "            if max_score == None or sim_score > max_score:\n",
    "                max_score = sim_score\n",
    "                max_loc = loc\n",
    "\n",
    "    if not similar:\n",
    "        pool_list.append(text)\n",
    "        encoding_dict[len(pool_list)-1] = text_encoding\n",
    "        match_dict[len(pool_list)-1] = []\n",
    "    else:\n",
    "        match_dict[max_loc].append((text, max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6e74ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"task1/data/feature_simi_final.jsonl\", \"w\") as out_f:\n",
    "    for indx in range(len(pool_list)):\n",
    "        list_ = match_dict[indx]\n",
    "        sorted_list = sorted(list_, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        if len(sorted_list) > 0:\n",
    "            tmp_dict = {pool_list[indx]: []}\n",
    "            for i in range(int(len(sorted_list)/2)):\n",
    "                tmp_dict[pool_list[indx]].append(sorted_list[i])\n",
    "        \n",
    "            out_f.write(str(tmp_dict)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c97aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6ef1866",
   "metadata": {},
   "source": [
    "# Scaling price column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1e75b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0196674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"task1/data/train_1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b49d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "train_df = pd.read_csv(input_file)\n",
    "price_series = train_df.price\n",
    "print(len(price_series))\n",
    "\n",
    "price_series.dropna(inplace=True)\n",
    "print(len(price_series))\n",
    "scaled_price = min_max_scaler.fit_transform(price_series)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
